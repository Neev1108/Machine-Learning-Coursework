{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>CS156 (Introduction to AI), Spring 2021</b>\n",
    "# <u><b>Homework 1 submission</b></u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roster Name: Neeval Kumar\n",
    "### Preferred Name (if different): Chosen Name\n",
    "### Student ID: 011877086\n",
    "### Email address: kumar.neeval@gmail.com\n",
    "Any special notes or anything you would like to communicate to me about this homework submission goes in here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <u>References and sources </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all your references and sources here.\n",
    "This includes all sites/discussion boards/blogs/posts/etc. where you grabbed some code examples.\n",
    "\n",
    "https://towardsdatascience.com/implement-gradient-descent-in-python-9b93ed7108d1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <u>Solution</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent works by imagining a space on a mountain and you would like to work yourself down the mountain. Let's make it so x represents our place on the mountain. We will randomly generate an x between -100, 100 (this works well with our iterations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from sympy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our chosen x will be -63.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "random_num = np.random.randint(-100,100)\n",
    "print(f'Our chosen x will be {random_num}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To reach the minimum, or the bottom of the mountain, we need to use a learning rate, which will represent our steps taken down the mountain. For this assignment, we will use a learning rate of .1\n",
    "\n",
    "#### The number of iterations will help us optimize our algorithm to reach the lowest height. We will use 100 iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .1\n",
    "num_iterations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The algorithm will work by finding derivative and take a step in the opposite of the gradient (in the negative direction)\n",
    "#### Stepping in the direction of the gradient will compute the highest ascent, so by doing the opposite, we are finding the min\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientdescent(random_num, learning_rate, num_iterations, y):\n",
    "    # First find the derivative\n",
    "    dydx = diff(y, x)\n",
    "    \n",
    "    # Make position equal to our random number, which represents our place on the hill\n",
    "    position = random_num\n",
    "    \n",
    "    # Go through iterations and step through\n",
    "    for i in range(num_iterations):\n",
    "        previous_position = position\n",
    "        position = position - learning_rate * dydx.evalf(subs= {x:previous_position})\n",
    "    \n",
    "    # At the last iteration, print the global minimum\n",
    "        if i + 1 == num_iterations:\n",
    "            print(f\"\\nGlobal Minimum is at x = {position}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global Minimum is at x = -0.333333333333333\n"
     ]
    }
   ],
   "source": [
    "x = symbols('x')\n",
    "y = 3 * (x ** 2) + (2 * x) - 4\n",
    "gradientdescent(random_num, learning_rate, num_iterations, y)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
